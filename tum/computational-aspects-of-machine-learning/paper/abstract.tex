\begin{abstract}
	Throughout the last decade available amount of data has grown ever rapidly, which posed a serious pressure onto existing machine learning algorithms. We will present overview of an approach dealing with the problem via on-line learning methods, while stressing its emergence within the large-scale data setting and showing some of the prallelization ideas as to surpass the inherent sequential nature of on-line optimizers, providing grounds for their scaling onto hundreds of cores in a distributed environment.
\end{abstract}
